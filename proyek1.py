# -*- coding: utf-8 -*-
"""Proyek1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qE7a0fehMfkHgFMvqqKMsqIAPUkkHTSl

# Project Machine Learning: Prediksi Penyakit Diabetes (Leni Fitriani)

#Import Library
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Mengatur tampilan grafik
sns.set(style="whitegrid")

"""Memuat Dataset lalu menampilkan 5 baris pertama data set untuk memahami strukturnya"""

# Memuat dataset dari path lengkap
data = pd.read_csv(r"/content/diabetes_prediction_dataset.csv")

# Menampilkan 5 baris pertama data untuk memahami strukturnya
data.head()

# Menampilkan informasi dataset
data.info()

"""Dari hasil analisis dataset, dapat disimpulkan bahwa:

1. **Tidak Ada Missing Values**:  
   Dataset ini tidak memiliki nilai yang hilang (**missing values**) pada seluruh fitur, sehingga dapat langsung digunakan untuk proses analisis dan pemodelan tanpa memerlukan proses imputasi.

2. **Fitur Kategori Perlu Encoding**:  
   Kolom kategori seperti `gender` dan `smoking_history` perlu diubah menjadi format numerik melalui proses encoding agar dapat diproses oleh algoritma machine learning.

3. **Data Siap Digunakan**:  
   Dataset sudah bersih dan lengkap, sehingga tidak diperlukan langkah tambahan untuk membersihkan data. Proses selanjutnya adalah menyiapkan data untuk pemodelan, termasuk normalisasi fitur numerik dan pembagian data menjadi data latih dan data uji.

#Data Understanding
"""

# Statistik deskriptif
data.describe()

"""## Statistik Deskriptif Dataset

Output di bawah ini memberikan informasi statistik deskriptif dari fitur numerik dalam dataset. Analisis ini penting untuk memahami distribusi, skala, dan variabilitas data.

| **Statistik**       | **Penjelasan**                                                                                                                                 |
|----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------|
| **`count`**         | Jumlah nilai (observasi) yang tersedia untuk setiap kolom. Semua kolom memiliki **100,000 entri**, menunjukkan tidak ada nilai yang hilang.   |
| **`mean`**          | Rata-rata nilai untuk setiap kolom. Memberikan gambaran umum tentang nilai tengah dari data.                                                  |
| **`std`**           | Standar deviasi, yang mengukur seberapa tersebar data dari rata-rata. Nilai yang besar menunjukkan variasi data yang tinggi.                  |
| **`min`**           | Nilai minimum dalam setiap kolom.                                                                                                             |
| **`25% (Q1)`**      | Kuartil pertama (25% data di bawah nilai ini).                                                                                                |
| **`50% (Median)`**  | Nilai tengah data, menunjukkan median (50% data di bawah dan di atas nilai ini).                                                              |
| **`75% (Q3)`**      | Kuartil ketiga (75% data di bawah nilai ini).                                                                                                |
| **`max`**           | Nilai maksimum dalam setiap kolom.                                                                                                            |

---

### Penjelasan Fitur-Fitur Utama

1. **Usia (`age`)**:
   - Rentang usia pasien adalah **0.08 tahun** (mungkin data anomali) hingga **80 tahun**.
   - Rata-rata usia adalah **41.88 tahun**, dengan standar deviasi **22.52**, menunjukkan variasi usia yang cukup besar.

2. **Hipertensi (`hypertension`)**:
   - Data biner dengan nilai **0** (tidak memiliki hipertensi) atau **1** (memiliki hipertensi).
   - Rata-rata **0.07485**, menunjukkan bahwa sekitar **7.48%** pasien memiliki hipertensi.

3. **Penyakit Jantung (`heart_disease`)**:
   - Data biner dengan nilai **0** (tidak memiliki penyakit jantung) atau **1** (memiliki penyakit jantung).
   - Rata-rata **0.03942**, menunjukkan bahwa sekitar **3.94%** pasien memiliki penyakit jantung.

4. **Indeks Massa Tubuh (`bmi`)**:
   - Rata-rata BMI pasien adalah **27.32**, dengan nilai maksimum **95.69**, yang kemungkinan merupakan outlier.
   - Standar deviasi sebesar **6.63**, menunjukkan penyebaran nilai BMI yang cukup signifikan.

5. **HbA1c Level (`HbA1c_level`)**:
   - Rata-rata kadar HbA1c adalah **5.53**, dengan minimum **3.5** dan maksimum **9.0**.
   - Standar deviasi **1.07**, menunjukkan bahwa distribusi nilai HbA1c cukup sempit.

6. **Kadar Gula Darah (`blood_glucose_level`)**:
   - Rata-rata kadar gula darah adalah **138.06 mg/dL**, dengan nilai maksimum **300 mg/dL** yang menunjukkan kemungkinan diabetes berat.
   - Standar deviasi **40.71**, menunjukkan distribusi kadar gula darah yang cukup luas.

7. **Diabetes (`diabetes`)**:
   - Target variabel dengan nilai biner (1: memiliki diabetes, 0: tidak memiliki diabetes).
   - Rata-rata **0.085**, menunjukkan bahwa hanya **8.5%** pasien dalam dataset yang didiagnosis memiliki diabetes.

- **Distribusi Data**: Data memiliki variasi yang luas di beberapa kolom, seperti `age` dan `blood_glucose_level`.
- **Outlier**: Beberapa fitur, seperti `bmi`, memiliki nilai maksimum yang jauh dari rata-rata, yang perlu diperiksa lebih lanjut untuk kemungkinan outlier.
- **Imbalanced Target**: Variabel target `diabetes` tidak seimbang, dengan hanya **8.5%** pasien yang memiliki diabetes. Hal ini perlu diperhatikan dalam pemodelan untuk menghindari bias model.
"""

# Mengecek apakah ada missing values
data.isnull().sum()

"""# Exploratory Data Analysis (EDA)

- Untuk memahami distribusi fitur dan pola yang ada dalam data, dilakukan beberapa analisis data eksploratif, termasuk visualisasi distribusi data untuk fitur utama.
"""

# Visualisasi distribusi usia
sns.histplot(data['age'], kde=True)
plt.title("Distribusi Usia")
plt.xlabel("Usia")
plt.ylabel("Frekuensi")
plt.show()

"""## Statistik Deskriptif Dataset

Output di bawah ini memberikan informasi statistik deskriptif dari fitur numerik dalam dataset. Analisis ini penting untuk memahami distribusi, skala, dan variabilitas data.

| **Statistik**       | **Penjelasan**                                                                                                                                 |
|----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------|
| **`count`**         | Jumlah nilai (observasi) yang tersedia untuk setiap kolom. Semua kolom memiliki **100,000 entri**, menunjukkan tidak ada nilai yang hilang.   |
| **`mean`**          | Rata-rata nilai untuk setiap kolom. Memberikan gambaran umum tentang nilai tengah dari data.                                                  |
| **`std`**           | Standar deviasi, yang mengukur seberapa tersebar data dari rata-rata. Nilai yang besar menunjukkan variasi data yang tinggi.                  |
| **`min`**           | Nilai minimum dalam setiap kolom.                                                                                                             |
| **`25% (Q1)`**      | Kuartil pertama (25% data di bawah nilai ini).                                                                                                |
| **`50% (Median)`**  | Nilai tengah data, menunjukkan median (50% data di bawah dan di atas nilai ini).                                                              |
| **`75% (Q3)`**      | Kuartil ketiga (75% data di bawah nilai ini).                                                                                                |
| **`max`**           | Nilai maksimum dalam setiap kolom.                                                                                                            |

---

### Penjelasan Fitur-Fitur Utama

1. **Usia (`age`)**:
   - Rentang usia pasien adalah **0.08 tahun** (mungkin data anomali) hingga **80 tahun**.
   - Rata-rata usia adalah **41.88 tahun**, dengan standar deviasi **22.52**, menunjukkan variasi usia yang cukup besar.

2. **Hipertensi (`hypertension`)**:
   - Data biner dengan nilai **0** (tidak memiliki hipertensi) atau **1** (memiliki hipertensi).
   - Rata-rata **0.07485**, menunjukkan bahwa sekitar **7.48%** pasien memiliki hipertensi.

3. **Penyakit Jantung (`heart_disease`)**:
   - Data biner dengan nilai **0** (tidak memiliki penyakit jantung) atau **1** (memiliki penyakit jantung).
   - Rata-rata **0.03942**, menunjukkan bahwa sekitar **3.94%** pasien memiliki penyakit jantung.

4. **Indeks Massa Tubuh (`bmi`)**:
   - Rata-rata BMI pasien adalah **27.32**, dengan nilai maksimum **95.69**, yang kemungkinan merupakan outlier.
   - Standar deviasi sebesar **6.63**, menunjukkan penyebaran nilai BMI yang cukup signifikan.

5. **HbA1c Level (`HbA1c_level`)**:
   - Rata-rata kadar HbA1c adalah **5.53**, dengan minimum **3.5** dan maksimum **9.0**.
   - Standar deviasi **1.07**, menunjukkan bahwa distribusi nilai HbA1c cukup sempit.

6. **Kadar Gula Darah (`blood_glucose_level`)**:
   - Rata-rata kadar gula darah adalah **138.06 mg/dL**, dengan nilai maksimum **300 mg/dL** yang menunjukkan kemungkinan diabetes berat.
   - Standar deviasi **40.71**, menunjukkan distribusi kadar gula darah yang cukup luas.

7. **Diabetes (`diabetes`)**:
   - Target variabel dengan nilai biner (1: memiliki diabetes, 0: tidak memiliki diabetes).
   - Rata-rata **0.085**, menunjukkan bahwa hanya **8.5%** pasien dalam dataset yang didiagnosis memiliki diabetes.

---

### Kesimpulan
- **Distribusi Data**: Data memiliki variasi yang luas di beberapa kolom, seperti `age` dan `blood_glucose_level`.
- **Outlier**: Beberapa fitur, seperti `bmi`, memiliki nilai maksimum yang jauh dari rata-rata, yang perlu diperiksa lebih lanjut untuk kemungkinan outlier.
- **Imbalanced Target**: Variabel target `diabetes` tidak seimbang, dengan hanya **8.5%** pasien yang memiliki diabetes. Hal ini perlu diperhatikan dalam pemodelan untuk menghindari bias model.
"""

# Visualisasi distribusi BMI
sns.histplot(data['bmi'], kde=True)
plt.title("Distribusi Body Mass Index (BMI)")
plt.xlabel("BMI")
plt.ylabel("Frekuensi")
plt.show()

"""## Exploratory Data Analysis (EDA): Distribusi Body Mass Index (BMI)

### Visualisasi Distribusi BMI
Grafik di atas menunjukkan distribusi Body Mass Index (BMI) pasien dalam dataset. Histogram digunakan untuk menampilkan frekuensi nilai BMI, sementara garis **Kernel Density Estimate (KDE)** membantu menggambarkan pola distribusi data secara keseluruhan.

### Interpretasi:
1. **Puncak Distribusi**:
   - Nilai BMI mayoritas pasien berada pada rentang **20 hingga 30**, dengan puncak yang sangat tinggi mendekati **27**. Ini menunjukkan bahwa sebagian besar pasien memiliki BMI dalam kategori **berat badan normal hingga kelebihan berat badan**.

2. **Nilai Ekstrem**:
   - BMI minimum tercatat di angka **10**, sedangkan nilai maksimum mendekati **95**. Nilai-nilai ekstrem ini kemungkinan merupakan **outlier** yang perlu ditangani dalam proses data preparation.

3. **Variasi yang Rendah**:
   - Grafik menunjukkan distribusi BMI yang cukup sempit dengan sebagian besar pasien terkonsentrasi dalam rentang tertentu (20-30), sementara sedikit pasien yang memiliki BMI sangat rendah (<20) atau sangat tinggi (>40).

### Kesimpulan:
- Sebagian besar pasien dalam dataset memiliki BMI yang normal hingga kelebihan berat badan.
- Outlier dengan nilai BMI yang terlalu tinggi atau rendah perlu diperhatikan untuk memastikan mereka tidak memberikan bias pada model.
- BMI merupakan salah satu fitur penting yang berpotensi memiliki korelasi dengan risiko diabetes, sehingga memerlukan analisis lebih lanjut untuk melihat signifikansinya terhadap variabel target.

"""

# Visualisasi distribusi diabetes
sns.countplot(x='diabetes', data=data)
plt.title("Distribusi Diabetes (Outcome)")
plt.xlabel("Diabetes (1: Diabetes, 0: Tidak Diabetes)")
plt.ylabel("Jumlah")
plt.show()

"""## Exploratory Data Analysis (EDA): Distribusi Diabetes (Outcome)

### Visualisasi Distribusi Diabetes
Grafik di atas menunjukkan distribusi label target `diabetes` dalam dataset. Nilai `1` menunjukkan pasien yang terdiagnosis diabetes, sedangkan nilai `0` menunjukkan pasien yang tidak terdiagnosis diabetes.

### Interpretasi:
1. **Imbalanced Dataset**:
   - Sebagian besar data didominasi oleh pasien yang **tidak memiliki diabetes** (label `0`), dengan jumlah lebih dari **90,000 pasien**.
   - Hanya sebagian kecil pasien, sekitar **8,500 pasien**, yang terdiagnosis diabetes (label `1`).
   - Perbandingan yang tidak seimbang ini mengindikasikan bahwa dataset memiliki masalah **class imbalance**, yang perlu diperhatikan dalam proses pemodelan untuk menghindari bias model terhadap kelas mayoritas.

2. **Distribusi Proporsi**:
   - Proporsi kelas pasien yang tidak terdiagnosis diabetes (label `0`) adalah sekitar **91.5%**, sementara pasien yang terdiagnosis diabetes (label `1`) adalah **8.5%** dari total dataset.

### Kesimpulan:
- **Penanganan Class Imbalance**:
  Mengingat ketidakseimbangan kelas ini, diperlukan teknik tertentu seperti **oversampling (SMOTE)** atau **undersampling** untuk memastikan model tidak hanya fokus pada kelas mayoritas.
- Distribusi ini menunjukkan bahwa diabetes merupakan kondisi yang relatif jarang terjadi dalam populasi yang ada pada dataset ini.

"""

# Visualisasi hubungan hipertensi dan diabetes
sns.countplot(x='hypertension', hue='diabetes', data=data)
plt.title("Distribusi Hipertensi Berdasarkan Kondisi Diabetes")
plt.xlabel("Hipertensi (0: Tidak, 1: Ya)")
plt.ylabel("Jumlah")
plt.legend(title="Diabetes", labels=["Tidak", "Ya"])
plt.show()

"""## Exploratory Data Analysis (EDA): Hubungan Hipertensi dan Diabetes

### Visualisasi Distribusi Hipertensi Berdasarkan Kondisi Diabetes
Grafik di atas menunjukkan distribusi pasien dengan atau tanpa hipertensi (`hypertension`) berdasarkan kondisi diabetes (`diabetes`).

- **Hipertensi (0)**: Pasien tidak memiliki riwayat hipertensi.
- **Hipertensi (1)**: Pasien memiliki riwayat hipertensi.
- **Diabetes (0)**: Pasien tidak terdiagnosis diabetes.
- **Diabetes (1)**: Pasien terdiagnosis diabetes.

### Interpretasi:
1. **Mayoritas Pasien Tidak Memiliki Hipertensi**:
   - Sebagian besar pasien dalam dataset tidak memiliki hipertensi (`hypertension = 0`), baik mereka yang terdiagnosis diabetes maupun tidak.
   - Pasien tanpa hipertensi yang tidak memiliki diabetes mendominasi data, dengan jumlah yang sangat tinggi (lebih dari **80,000 pasien**).

2. **Kondisi Hipertensi dan Diabetes**:
   - Untuk pasien dengan riwayat hipertensi (`hypertension = 1`), terdapat proporsi yang lebih besar dari pasien yang terdiagnosis diabetes dibandingkan pasien tanpa hipertensi.
   - Hal ini menunjukkan adanya keterkaitan antara hipertensi dan kemungkinan seseorang terdiagnosis diabetes.

3. **Distribusi Diabetes di Kelompok Non-Hipertensi**:
   - Di antara pasien tanpa hipertensi (`hypertension = 0`), sebagian kecil pasien terdiagnosis diabetes. Ini menunjukkan bahwa tidak semua kasus diabetes berkaitan langsung dengan hipertensi.

### Kesimpulan:
- **Keterkaitan Hipertensi dan Diabetes**:
  Grafik ini menunjukkan bahwa pasien dengan hipertensi cenderung memiliki risiko lebih tinggi untuk terdiagnosis diabetes dibandingkan pasien tanpa hipertensi.
- Informasi ini dapat digunakan untuk mengidentifikasi faktor risiko tambahan dalam prediksi diabetes.

"""

# Mengambil hanya kolom numerik untuk perhitungan korelasi
numeric_data = data.select_dtypes(include=[float, int])

# Menampilkan heatmap korelasi
plt.figure(figsize=(10, 8))
sns.heatmap(numeric_data.corr(), annot=True, cmap="YlGnBu")
plt.title("Matriks Korelasi")
plt.show()

"""## Exploratory Data Analysis (EDA): Matriks Korelasi

### Visualisasi Matriks Korelasi
Grafik di atas adalah heatmap korelasi yang menunjukkan hubungan antar fitur numerik dalam dataset, termasuk `diabetes` sebagai variabel target. Nilai korelasi berkisar dari -1 hingga 1:
- **Nilai positif**: Menunjukkan korelasi positif, di mana peningkatan satu variabel diikuti oleh peningkatan variabel lainnya.
- **Nilai negatif**: Menunjukkan korelasi negatif, di mana peningkatan satu variabel diikuti oleh penurunan variabel lainnya.
- **Nilai mendekati nol**: Menunjukkan tidak adanya hubungan linear yang signifikan antara dua variabel.

### Interpretasi:
1. **Fitur yang Berkorelasi Tinggi dengan Diabetes**:
   - `blood_glucose_level` memiliki korelasi tertinggi dengan diabetes (**0.42**), menunjukkan bahwa kadar glukosa darah sangat relevan dalam prediksi diabetes.
   - `HbA1c_level` juga menunjukkan korelasi yang signifikan (**0.4**), mengindikasikan bahwa kadar HbA1c relevan dalam diagnosis diabetes.

2. **Fitur Lain yang Relevan**:
   - `age` memiliki korelasi sebesar **0.26**, menunjukkan bahwa usia memiliki hubungan moderat dengan risiko diabetes.
   - `bmi` memiliki korelasi sebesar **0.21**, yang menunjukkan pengaruh moderat dari indeks massa tubuh terhadap kemungkinan diabetes.

3. **Fitur dengan Korelasi Rendah**:
   - `heart_disease` (**0.17**) dan `hypertension` (**0.2**) memiliki korelasi yang rendah terhadap diabetes, menunjukkan pengaruh yang lebih kecil dalam model prediksi.

### Kesimpulan:
- Heatmap ini membantu mengidentifikasi fitur-fitur yang relevan untuk model prediksi diabetes.
- Fitur `blood_glucose_level` dan `HbA1c_level` adalah prediktor kuat untuk diabetes dan harus menjadi fokus dalam pemodelan.
- Korelasi rendah pada beberapa fitur tidak berarti mereka tidak penting, tetapi kontribusinya terhadap model kemungkinan lebih kecil.

"""

# Mengonversi kolom kategori menjadi variabel dummy
data_encoded = pd.get_dummies(data, columns=['gender'], drop_first=True)

# Mengambil hanya kolom numerik
numeric_data = data_encoded.select_dtypes(include=[float, int])

# Menampilkan heatmap korelasi
plt.figure(figsize=(10, 8))
sns.heatmap(numeric_data.corr(), annot=True, cmap="YlGnBu")
plt.title("Matriks Korelasi dengan Variabel Dummy")
plt.show()

"""## Exploratory Data Analysis (EDA): Matriks Korelasi dengan Variabel Dummy

### Visualisasi Matriks Korelasi
Grafik di atas adalah heatmap yang menampilkan korelasi antar fitur numerik dalam dataset, termasuk variabel dummy `diabetes` sebagai target. Korelasi dihitung berdasarkan hubungan linear antar variabel, dengan nilai berkisar antara -1 hingga 1:
- **Korelasi positif**: Nilai positif menunjukkan bahwa ketika satu variabel meningkat, variabel lainnya juga cenderung meningkat.
- **Korelasi negatif**: Nilai negatif menunjukkan bahwa ketika satu variabel meningkat, variabel lainnya cenderung menurun.
- **Korelasi mendekati nol**: Menunjukkan hubungan linear yang lemah atau tidak ada.

### Analisis:
1. **Fitur dengan Korelasi Tinggi terhadap `diabetes`**:
   - `blood_glucose_level` memiliki korelasi tertinggi (**0.42**) terhadap diabetes, mengindikasikan relevansi besar dalam memprediksi risiko diabetes.
   - `HbA1c_level` juga memiliki korelasi kuat (**0.4**), yang menunjukkan kontribusi signifikan dalam model.

2. **Fitur Lainnya**:
   - `age` memiliki korelasi moderat sebesar **0.26**, menandakan adanya hubungan antara usia dan risiko diabetes.
   - `bmi` memiliki korelasi sebesar **0.21**, menunjukkan bahwa indeks massa tubuh juga merupakan faktor yang memengaruhi.

3. **Fitur dengan Korelasi Rendah**:
   - `heart_disease` (**0.17**) dan `hypertension` (**0.2**) memiliki korelasi rendah terhadap diabetes, mengindikasikan pengaruh yang kecil dibandingkan fitur lainnya.

### Kesimpulan:
- Heatmap ini mengidentifikasi fitur penting seperti `blood_glucose_level` dan `HbA1c_level` sebagai prediktor kuat untuk diabetes.
- Fitur lain seperti `age` dan `bmi` juga relevan, meskipun dengan pengaruh yang lebih kecil.
- Informasi dari matriks korelasi ini dapat digunakan untuk menyusun strategi pemodelan yang lebih efektif.

# Data Preparation

Data preparation adalah proses yang dilakukan untuk mempersiapkan dataset agar siap digunakan dalam proses analisis dan pemodelan machine learning. Tahapan ini bertujuan untuk memastikan bahwa data dalam kondisi bersih, terstruktur, dan sesuai dengan format yang dibutuhkan oleh algoritma machine learning. Berikut adalah tujuan utama dari data preparation:

1. **Mengatasi Data Kategori**:
   - Data kategori seperti `gender` dan `smoking_history` tidak dapat digunakan langsung oleh algoritma machine learning yang membutuhkan data numerik. Oleh karena itu, data kategori diubah menjadi variabel dummy menggunakan teknik One-Hot Encoding.

2. **Pemisahan Fitur dan Target**:
   - Proses ini membagi dataset menjadi dua bagian: fitur (`X`) dan target (`y`). Fitur (`X`) mencakup semua kolom yang menjadi input untuk model, sementara target (`y`) adalah kolom yang menjadi output yang ingin diprediksi. Dalam kasus ini, kolom `diabetes` menjadi target.

3. **Meningkatkan Kualitas Data**:
   - Melalui normalisasi atau encoding, data menjadi lebih terstandarisasi sehingga algoritma machine learning dapat bekerja dengan optimal. Langkah-langkah seperti ini membantu mencegah bias model akibat nilai yang tidak konsisten atau tidak sesuai.

Dengan melakukan data preparation, kualitas data yang digunakan dalam analisis meningkat sehingga menghasilkan model prediksi yang lebih akurat dan dapat diandalkan.
"""

# Mengonversi kolom kategori menjadi variabel dummy
data_encoded = pd.get_dummies(data, columns=['gender', 'smoking_history'], drop_first=True)

"""

1. **Mengonversi Kolom Kategori menjadi Variabel Dummy**:
   - Kolom kategori seperti `gender` dan `smoking_history` diubah menjadi variabel dummy menggunakan teknik One-Hot Encoding.
   - Hal ini dilakukan agar data kategori dapat digunakan dalam model machine learning yang hanya menerima data numerik.

2. **Memisahkan Fitur (X) dan Target (y)**:
   - Dataset dipisahkan menjadi fitur (`X`) dan target (`y`), di mana `X` berisi semua kolom kecuali `diabetes`, dan `y` hanya berisi kolom `diabetes`.
   - Pemisahan ini bertujuan untuk mempersiapkan data bagi proses pelatihan model machine learning.

Langkah-langkah ini memastikan bahwa dataset sudah dalam format yang sesuai dan siap digunakan untuk proses analisis dan pemodelan lebih lanjut.
"""

# Memisahkan fitur (X) dan target (y)
X = data_encoded.drop('diabetes', axis=1)
y = data_encoded['diabetes']

from sklearn.preprocessing import MinMaxScaler

# Inisialisasi MinMaxScaler
scaler = MinMaxScaler()

# Menerapkan normalisasi pada fitur numerik
X_scaled = scaler.fit_transform(X)

# Jika ingin hasilnya dalam bentuk DataFrame kembali
X = pd.DataFrame(X_scaled, columns=X.columns)

"""### Normalisasi dan Pembagian Data

1. **Normalisasi Data Numerik**
   - Proses normalisasi dilakukan menggunakan `MinMaxScaler` dari library `sklearn`. Normalisasi bertujuan untuk menyelaraskan skala fitur numerik seperti `age`, `bmi`, `HbA1c_level`, dan `blood_glucose_level` agar berada dalam rentang 0 hingga 1. Hal ini penting karena model machine learning sensitif terhadap skala data, sehingga normalisasi dapat membantu meningkatkan kinerja model.

   - Contoh kode:
     ```python
     from sklearn.preprocessing import MinMaxScaler
     scaler = MinMaxScaler()
     X_scaled = scaler.fit_transform(X)
     X = pd.DataFrame(X_scaled, columns=X.columns)
     ```

2. **Pembagian Data**
   - Dataset dibagi menjadi data latih (`X_train`, `y_train`) dan data uji (`X_test`, `y_test`) dengan rasio 80:20 menggunakan fungsi `train_test_split`. Data latih digunakan untuk melatih model, sedangkan data uji digunakan untuk mengevaluasi performa model.
   - Proses pembagian dilakukan dengan parameter `random_state=42` agar hasil pembagian dapat direproduksi.

   - Contoh kode:
     ```python
     from sklearn.model_selection import train_test_split
     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
     ```

"""

from sklearn.model_selection import train_test_split

# Membagi data menjadi data latih dan data uji (80:20)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Melihat beberapa baris pertama dari data yang telah diproses
data_encoded.head()

"""3. **Memeriksa Data yang Telah Diproses**
   - Setelah proses normalisasi dan encoding, data yang telah diproses diperiksa menggunakan fungsi `head()` untuk memastikan semua fitur berada dalam format yang sesuai untuk analisis lebih lanjut.
4. **Manfaat Langkah Ini**
   - Normalisasi memastikan data berada dalam skala yang seragam, sehingga model lebih stabil dalam melakukan perhitungan.
   - Pembagian data latih dan uji penting untuk memisahkan data yang digunakan untuk melatih model dan mengevaluasinya, sehingga dapat meminimalkan risiko overfitting.
"""

# Melihat data setelah normalisasi
pd.DataFrame(X_scaled, columns=X.columns).head()

"""### Data Setelah Normalisasi

Setelah proses normalisasi, semua fitur numerik telah disesuaikan dalam rentang nilai 0 hingga 1. Berikut adalah hasil data setelah normalisasi:

| **age**   | **hypertension** | **heart_disease** | **bmi**     | **HbA1c_level** | **blood_glucose_level** | **gender_Male** | **gender_Other** | **smoking_history_current** | **smoking_history_ever** | **smoking_history_former** | **smoking_history_never** | **smoking_history_not current** |
|-----------|------------------|-------------------|-------------|-----------------|-------------------------|-----------------|------------------|-----------------------------|--------------------------|-----------------------------|---------------------------|--------------------------------|
| 1.000000  | 0.0              | 1.0               | 0.177171    | 0.563636        | 0.272727                | 0.0             | 0.0              | 0.0                         | 0.0                      | 0.0                         | 1.0                       | 0.0                            |
| 0.674675  | 0.0              | 0.0               | 0.202031    | 0.563636        | 0.000000                | 0.0             | 0.0              | 0.0                         | 0.0                      | 0.0                         | 0.0                       | 0.0                            |
| 0.349349  | 0.0              | 0.0               | 0.202031    | 0.400000        | 0.354545                | 1.0             | 0.0              | 0.0                         | 0.0                      | 0.0                         | 1.0                       | 0.0                            |
| 0.449449  | 0.0              | 0.0               | 0.156863    | 0.272727        | 0.340909                | 0.0             | 0.0              | 1.0                         | 0.0                      | 0.0                         | 0.0                       | 0.0                            |
| 0.949950  | 1.0              | 1.0               | 0.118231    | 0.236364        | 0.340909                | 1.0             | 0.0              | 1.0                         | 0.0                      | 0.0                         | 0.0                       | 0.0                            |

### Penjelasan Kolom:
1. **Fitur Numerik:**
   - Fitur seperti `age`, `bmi`, `HbA1c_level`, dan `blood_glucose_level` telah dinormalisasi ke rentang 0-1 menggunakan **MinMaxScaler**.
   - Normalisasi membantu menjaga konsistensi skala antar fitur untuk mencegah bias terhadap fitur dengan nilai lebih besar.

2. **Variabel Dummy:**
   - Fitur kategorikal seperti `gender` dan `smoking_history` diubah menjadi variabel dummy. Misalnya:
     - `gender_Male`: 1 untuk laki-laki, 0 untuk lainnya.
     - `smoking_history_current`: 1 jika merokok saat ini, 0 jika tidak.

### Manfaat Normalisasi:
- Membantu algoritma machine learning yang berbasis gradien, seperti logistic regression dan neural network, untuk berfungsi lebih efisien.
- Mengurangi sensitivitas model terhadap fitur dengan skala yang berbeda.

"""

# Memeriksa bentuk data latih dan data uji
print("Data latih (X_train):", X_train.shape)
print("Data uji (X_test):", X_test.shape)
print("Target latih (y_train):", y_train.shape)
print("Target uji (y_test):", y_test.shape)

"""### Pemisahan Data Latih dan Data Uji

Setelah melakukan proses normalisasi dan encoding, data dibagi menjadi dua bagian:
1. **Data Latih (Training Data):** Digunakan untuk melatih model.
2. **Data Uji (Testing Data):** Digunakan untuk mengevaluasi kinerja model.

Berikut adalah rincian jumlah data:
- **Data Latih (X_train):** 80,000 baris dengan 13 fitur.
- **Data Uji (X_test):** 20,000 baris dengan 13 fitur.
- **Target Latih (y_train):** 80,000 baris untuk label target.
- **Target Uji (y_test):** 20,000 baris untuk label target.

### Penjelasan Proses:
1. **Pemisahan Data:**
   - Data dibagi menggunakan fungsi `train_test_split` dari scikit-learn.
   - Pembagian dilakukan dengan rasio 80:20 (80% data latih dan 20% data uji).
   - Parameter `random_state=42` digunakan untuk memastikan hasil pembagian konsisten di setiap eksekusi.

2. **Manfaat Pembagian:**
   - Data latih digunakan untuk membangun model.
   - Data uji digunakan untuk mengevaluasi apakah model dapat bekerja baik pada data yang belum pernah dilihat.

### Output:
- Data terbagi secara proporsional sehingga memastikan jumlah data yang cukup baik untuk pelatihan maupun evaluasi.

"""

# Melihat distribusi target pada data latih dan data uji
print("Distribusi target pada data latih:")
print(y_train.value_counts(normalize=True))

print("\nDistribusi target pada data uji:")
print(y_test.value_counts(normalize=True))

"""### Distribusi Target pada Data Latih dan Data Uji

Setelah data dibagi menjadi data latih dan data uji, dilakukan pemeriksaan distribusi target untuk memastikan bahwa data terdistribusi secara proporsional di kedua bagian.

#### Hasil Distribusi:
1. **Distribusi Target pada Data Latih:**
   - **Label 0 (Tidak Diabetes):** 91.51%
   - **Label 1 (Diabetes):** 8.49%

2. **Distribusi Target pada Data Uji:**
   - **Label 0 (Tidak Diabetes):** 91.46%
   - **Label 1 (Diabetes):** 8.54%

#### Analisis:
- Distribusi target pada data latih dan data uji relatif seimbang dan proporsional, mencerminkan distribusi pada dataset asli.
- Hal ini penting untuk menjaga representasi data dalam model, terutama ketika bekerja dengan dataset yang memiliki ketidakseimbangan label seperti kasus ini.

#### Kesimpulan:
Distribusi target yang konsisten memastikan bahwa model dapat belajar secara adil dari data latih dan dievaluasi secara akurat menggunakan data uji.

# Model Development
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Inisialisasi dan pelatihan model Logistic Regression
logreg_model = LogisticRegression(random_state=42)
logreg_model.fit(X_train, y_train)

# Prediksi dengan Logistic Regression
y_pred_logreg = logreg_model.predict(X_test)

# Evaluasi
accuracy_logreg = accuracy_score(y_test, y_pred_logreg)
precision_logreg = precision_score(y_test, y_pred_logreg)
recall_logreg = recall_score(y_test, y_pred_logreg)
f1_logreg = f1_score(y_test, y_pred_logreg)
print(f"Logistic Regression - Akurasi: {accuracy_logreg:.2f}, F1 Score: {f1_logreg:.2f}")

"""### Logistic Regression Model

Pada tahap ini, model **Logistic Regression** digunakan untuk memprediksi kemungkinan seseorang memiliki diabetes berdasarkan data fitur.

#### Proses:
1. **Inisialisasi dan Pelatihan Model:**
   - Model Logistic Regression diinisialisasi dengan `random_state=42` untuk memastikan hasil yang konsisten.
   - Model dilatih menggunakan data latih (`X_train` dan `y_train`).

2. **Prediksi:**
   - Model melakukan prediksi pada data uji (`X_test`).

3. **Evaluasi Model:**
   - Metode evaluasi yang digunakan meliputi:
     - **Accuracy:** Mengukur persentase prediksi benar.
     - **Precision:** Mengukur kemampuan model dalam memprediksi kelas positif secara benar.
     - **Recall:** Mengukur kemampuan model dalam menangkap semua instance kelas positif.
     - **F1 Score:** Menggabungkan precision dan recall ke dalam satu metrik harmonis.

#### Hasil Evaluasi:
- **Akurasi:** 96%
- **F1 Score:** 72%

#### Analisis:
- Model Logistic Regression menunjukkan akurasi yang tinggi, menandakan bahwa model dapat memprediksi dengan baik sebagian besar data.
- Nilai F1 Score sebesar 72% mencerminkan kinerja yang cukup baik dalam menangani keseimbangan antara precision dan recall, meskipun dataset memiliki ketidakseimbangan label.

#### Kesimpulan:
Model Logistic Regression adalah baseline yang kuat untuk memulai prediksi diabetes, memberikan hasil akurasi yang baik.

"""

from sklearn.ensemble import RandomForestClassifier

# Inisialisasi dan pelatihan model Random Forest
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)

# Prediksi dengan Random Forest
y_pred_rf = rf_model.predict(X_test)

# Evaluasi
accuracy_rf = accuracy_score(y_test, y_pred_rf)
precision_rf = precision_score(y_test, y_pred_rf)
recall_rf = recall_score(y_test, y_pred_rf)
f1_rf = f1_score(y_test, y_pred_rf)
print(f"Random Forest - Akurasi: {accuracy_rf:.2f}, F1 Score: {f1_rf:.2f}")

"""### Random Forest Model

Pada tahap ini, model **Random Forest** digunakan untuk memprediksi kemungkinan seseorang memiliki diabetes berdasarkan data fitur.

#### Proses:
1. **Inisialisasi dan Pelatihan Model:**
   - Model Random Forest diinisialisasi dengan `random_state=42` untuk memastikan hasil yang konsisten.
   - Model dilatih menggunakan data latih (`X_train` dan `y_train`).

2. **Prediksi:**
   - Model melakukan prediksi pada data uji (`X_test`).

3. **Evaluasi Model:**
   - Metode evaluasi yang digunakan meliputi:
     - **Accuracy:** Mengukur persentase prediksi benar.
     - **Precision:** Mengukur kemampuan model dalam memprediksi kelas positif secara benar.
     - **Recall:** Mengukur kemampuan model dalam menangkap semua instance kelas positif.
     - **F1 Score:** Menggabungkan precision dan recall ke dalam satu metrik harmonis.

#### Hasil Evaluasi:
- **Akurasi:** 97%
- **F1 Score:** 80%

#### Analisis:
- Model Random Forest menunjukkan kinerja yang lebih baik dibandingkan Logistic Regression, dengan akurasi lebih tinggi.
- Nilai F1 Score sebesar 80% mencerminkan kinerja yang lebih seimbang dalam menangani precision dan recall, membuat model ini lebih unggul dalam menangani dataset yang tidak seimbang.

#### Kesimpulan:
Model Random Forest memberikan hasil yang lebih baik dibandingkan Logistic Regression, menjadikannya kandidat yang kuat untuk prediksi diabetes.

"""

from sklearn.svm import SVC

# Inisialisasi dan pelatihan model SVM
svm_model = SVC(random_state=42)
svm_model.fit(X_train, y_train)

# Prediksi dengan SVM
y_pred_svm = svm_model.predict(X_test)

# Evaluasi
accuracy_svm = accuracy_score(y_test, y_pred_svm)
precision_svm = precision_score(y_test, y_pred_svm)
recall_svm = recall_score(y_test, y_pred_svm)
f1_svm = f1_score(y_test, y_pred_svm)
print(f"SVM - Akurasi: {accuracy_svm:.2f}, F1 Score: {f1_svm:.2f}")

"""### Support Vector Machine (SVM)

Model **Support Vector Machine (SVM)** digunakan sebagai salah satu algoritma untuk memprediksi kemungkinan diabetes berdasarkan dataset yang ada.

#### Proses:
1. **Inisialisasi dan Pelatihan Model:**
   - Model SVM diinisialisasi dengan `random_state=42` untuk memastikan hasil konsisten.
   - Model dilatih menggunakan data latih (`X_train` dan `y_train`).

2. **Prediksi:**
   - Model melakukan prediksi terhadap data uji (`X_test`).

3. **Evaluasi Model:**
   - Evaluasi dilakukan dengan metrik berikut:
     - **Accuracy:** Persentase prediksi yang benar.
     - **Precision:** Kemampuan model dalam memprediksi kelas positif secara benar.
     - **Recall:** Kemampuan model dalam mendeteksi seluruh instance kelas positif.
     - **F1 Score:** Kombinasi harmonis antara precision dan recall.

#### Hasil Evaluasi:
- **Akurasi:** 96%
- **F1 Score:** 70%

#### Analisis:
- Model SVM menghasilkan akurasi yang cukup tinggi, yakni 96%, namun nilai **F1 Score** relatif lebih rendah dibandingkan model Random Forest.
- Hal ini menunjukkan bahwa meskipun akurasi tinggi, kemampuan model untuk menangani kelas yang tidak seimbang masih dapat ditingkatkan.

#### Kesimpulan:
Model SVM cocok untuk digunakan pada dataset ini, namun performanya lebih rendah dibandingkan Random Forest, terutama dalam hal keseimbangan precision dan recall, yang terlihat dari nilai F1 Score yang lebih kecil.

"""

from sklearn.svm import SVC

# Inisialisasi dan pelatihan model SVM
svm_model = SVC(random_state=42)
svm_model.fit(X_train, y_train)

# Prediksi dengan SVM
y_pred_svm = svm_model.predict(X_test)

# Evaluasi
accuracy_svm = accuracy_score(y_test, y_pred_svm)
precision_svm = precision_score(y_test, y_pred_svm)
recall_svm = recall_score(y_test, y_pred_svm)
f1_svm = f1_score(y_test, y_pred_svm)
print(f"SVM - Akurasi: {accuracy_svm:.2f}, F1 Score: {f1_svm:.2f}")

"""### Support Vector Machine (SVM)

Pada tahap ini, model **Support Vector Machine (SVM)** digunakan untuk memprediksi kemungkinan diabetes berdasarkan dataset yang telah disediakan.

#### Langkah-Langkah:
1. **Inisialisasi dan Pelatihan Model:**
   - Model SVM diinisialisasi menggunakan parameter default dan `random_state=42` untuk memastikan hasil yang konsisten.
   - Model dilatih dengan data latih (`X_train` dan `y_train`) untuk mempelajari pola dari data.

2. **Prediksi:**
   - Model memprediksi hasil untuk data uji (`X_test`), menghasilkan label prediksi (`y_pred_svm`).

3. **Evaluasi:**
   - Evaluasi performa model menggunakan metrik berikut:
     - **Accuracy:** Proporsi prediksi yang benar terhadap total data.
     - **Precision:** Proporsi prediksi positif yang benar.
     - **Recall:** Kemampuan model mendeteksi seluruh kasus positif.
     - **F1 Score:** Rata-rata harmonis antara precision dan recall untuk mengevaluasi keseimbangan keduanya.

#### Hasil Evaluasi:
- **Akurasi:** 96%
- **F1 Score:** 70%

#### Analisis:
- Akurasi yang cukup tinggi (96%) menunjukkan bahwa model mampu memprediksi dengan baik.
- Namun, F1 Score lebih rendah, mengindikasikan adanya ketidakseimbangan antara precision dan recall.

#### Kesimpulan:
Model SVM memberikan performa yang baik, tetapi dibandingkan dengan model lain seperti Random Forest, performanya masih kurang optimal untuk dataset ini.

"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

"""### Model Deep Learning Menggunakan Keras

Pada bagian ini, model Deep Learning dibuat dengan menggunakan library Keras yang tersedia di TensorFlow untuk memprediksi kemungkinan diabetes.

#### Arsitektur Model:
1. **Layer Input:**
   - **Dense Layer** pertama memiliki 64 neuron dengan fungsi aktivasi **ReLU**, dan menerima input dengan jumlah fitur sesuai data latih (`X_train.shape[1]`).

2. **Hidden Layer:**
   - **Dense Layer** kedua memiliki 32 neuron dengan fungsi aktivasi **ReLU**.

3. **Layer Output:**
   - **Dense Layer** terakhir memiliki 1 neuron dengan fungsi aktivasi **Sigmoid** untuk menghasilkan probabilitas prediksi dalam kasus biner.

#### Kompilasi Model:
- **Optimizer:** Adam dengan learning rate sebesar 0.001.
- **Loss Function:** Binary crossentropy digunakan karena ini adalah masalah klasifikasi biner.
- **Metrics:** Akurasi dipilih untuk memonitor performa model selama pelatihan.

#### Analisis:
- Penggunaan fungsi aktivasi **ReLU** pada hidden layers memastikan model dapat menangkap hubungan non-linear antara fitur dan target.
- Fungsi **Sigmoid** pada output layer memberikan nilai probabilitas antara 0 dan 1, sesuai kebutuhan prediksi diabetes.

#### Selanjutnya:
Model ini akan dilatih menggunakan data latih (`X_train` dan `y_train`) dengan beberapa epoch untuk mendapatkan hasil yang optimal.

"""

model_dl = Sequential([
    Dense(64, input_shape=(X_train.shape[1],), activation='relu'),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')
])

model_dl.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

history = model_dl.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)

"""### Hasil Pelatihan Model Deep Learning

Model dilatih menggunakan data latih dengan parameter sebagai berikut:
- **Jumlah Epochs:** 20
- **Batch Size:** 32
- **Validation Split:** 20% dari data latih digunakan sebagai data validasi.

#### Output Pelatihan:
Setiap epoch menghasilkan informasi berikut:
- **Accuracy:** Akurasi model pada data latih.
- **Loss:** Nilai loss pada data latih berdasarkan fungsi `binary_crossentropy`.
- **Validation Accuracy:** Akurasi model pada data validasi.
- **Validation Loss:** Nilai loss pada data validasi.

#### Kesimpulan:
Hasil pelatihan menunjukkan bahwa model memiliki performa yang baik pada data latih dan data validasi. Akurasi validasi yang tinggi dan nilai loss yang rendah menunjukkan bahwa model tidak mengalami overfitting.

"""

loss, accuracy_dl = model_dl.evaluate(X_test, y_test)
print(f"Deep Learning Model - Akurasi: {accuracy_dl:.2f}")

"""### Evaluasi Model Deep Learning

Setelah proses pelatihan selesai, model diuji menggunakan data uji untuk mengevaluasi kinerjanya pada data yang belum pernah dilihat sebelumnya.

#### Hasil Evaluasi:
- **Akurasi:** 0.97 (97%)
- **Loss:** 0.0875

#### Observasi:
1. Akurasi sebesar 97% menunjukkan bahwa model memiliki kemampuan yang sangat baik dalam memprediksi label diabetes pada data uji.
2. Nilai loss yang rendah (0.0875) mengindikasikan bahwa model memiliki generalisasi yang baik tanpa overfitting.

#### Kesimpulan:
Model Deep Learning berhasil mencapai performa yang tinggi pada data uji, menjadikannya salah satu model yang andal untuk digunakan dalam prediksi diabetes.

"""

import matplotlib.pyplot as plt

# Grafik Akurasi
plt.plot(history.history['accuracy'], label='Akurasi Training')
plt.plot(history.history['val_accuracy'], label='Akurasi Validasi')
plt.xlabel('Epoch')
plt.ylabel('Akurasi')
plt.legend()
plt.title('Akurasi Model Deep Learning Selama Pelatihan')
plt.show()

# Grafik Loss
plt.plot(history.history['loss'], label='Loss Training')
plt.plot(history.history['val_loss'], label='Loss Validasi')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Loss Model Deep Learning Selama Pelatihan')
plt.show()

"""### Visualisasi Akurasi dan Loss Model Deep Learning Selama Pelatihan

#### Grafik Akurasi
Grafik pertama menunjukkan tren akurasi model selama pelatihan untuk data latih dan validasi. Berikut beberapa poin penting:
- Akurasi untuk data latih meningkat secara konsisten selama proses pelatihan.
- Akurasi untuk data validasi juga meningkat, mengikuti pola serupa dengan data latih, menunjukkan bahwa model tidak mengalami overfitting.

#### Grafik Loss
Grafik kedua menggambarkan penurunan nilai loss selama pelatihan:
- Nilai loss untuk data latih menurun dengan stabil, menunjukkan bahwa model semakin baik dalam meminimalkan kesalahan.
- Nilai loss untuk data validasi juga menurun, mengikuti pola yang hampir sama dengan data latih, mengindikasikan generalisasi yang baik.

#### Kesimpulan
Berdasarkan kedua grafik, model deep learning menunjukkan performa yang stabil selama pelatihan, dengan akurasi yang tinggi dan loss yang rendah baik pada data latih maupun validasi.

"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Dictionary untuk menyimpan hasil setiap model
results = {}

# Evaluasi Logistic Regression
y_pred_logreg = logreg_model.predict(X_test)
results['Logistic Regression'] = [
    accuracy_score(y_test, y_pred_logreg),
    precision_score(y_test, y_pred_logreg),
    recall_score(y_test, y_pred_logreg),
    f1_score(y_test, y_pred_logreg)
]

# Evaluasi Random Forest
y_pred_rf = rf_model.predict(X_test)
results['Random Forest'] = [
    accuracy_score(y_test, y_pred_rf),
    precision_score(y_test, y_pred_rf),
    recall_score(y_test, y_pred_rf),
    f1_score(y_test, y_pred_rf)
]

# Evaluasi SVM
y_pred_svm = svm_model.predict(X_test)
results['SVM'] = [
    accuracy_score(y_test, y_pred_svm),
    precision_score(y_test, y_pred_svm),
    recall_score(y_test, y_pred_svm),
    f1_score(y_test, y_pred_svm)
]

# Evaluasi Deep Learning
y_pred_dl = (model_dl.predict(X_test) > 0.5).astype("int32")  # Konversi probabilitas ke kelas biner
results['Deep Learning'] = [
    accuracy_score(y_test, y_pred_dl),
    precision_score(y_test, y_pred_dl),
    recall_score(y_test, y_pred_dl),
    f1_score(y_test, y_pred_dl)
]

"""### Evaluasi Kinerja Model
Pada bagian ini, dilakukan evaluasi kinerja dari empat model: Logistic Regression, Random Forest, SVM, dan Deep Learning. Evaluasi menggunakan metrik sebagai berikut:
- **Akurasi**: Proporsi prediksi yang benar dari keseluruhan data.
- **Precision**: Proporsi prediksi positif yang benar-benar relevan.
- **Recall**: Proporsi data positif yang berhasil dikenali dengan benar.
- **F1 Score**: Harmonic mean dari precision dan recall, digunakan untuk menyeimbangkan kedua metrik.

"""

import pandas as pd

# Konversi hasil ke dalam DataFrame untuk tabel
results_df = pd.DataFrame(results, index=['Akurasi', 'Precision', 'Recall', 'F1 Score']).T
results_df

"""### Tabel Hasil Evaluasi Model
Tabel berikut menunjukkan hasil evaluasi dari keempat model yang telah diimplementasikan. Metrik yang digunakan meliputi Akurasi, Precision, Recall, dan F1 Score.

| Model               | Akurasi | Precision | Recall   | F1 Score |
|---------------------|---------|-----------|----------|----------|
| Logistic Regression | 0.95920 | 0.871048  | 0.612998 | 0.719588 |
| Random Forest       | 0.96995 | 0.946011  | 0.687354 | 0.796202 |
| SVM                 | 0.96010 | 0.967146  | 0.551522 | 0.702461 |
| Deep Learning       | 0.96960 | 0.935252  | 0.685012 | 0.790808 |

#### Analisis
1. **Akurasi**: Random Forest dan Deep Learning memiliki nilai akurasi tertinggi (0.97).
2. **Precision**: SVM menunjukkan precision tertinggi (0.967), mengindikasikan kemampuan terbaik dalam mengidentifikasi prediksi positif yang benar.
3. **Recall**: Random Forest dan Deep Learning memiliki nilai recall yang lebih baik dibanding Logistic Regression dan SVM, menunjukkan model ini lebih efektif dalam menangkap data positif.
4. **F1 Score**: Random Forest memiliki F1 score tertinggi, menjadikannya model yang paling seimbang antara precision dan recall.

Dari hasil ini, **Random Forest** dipilih sebagai model terbaik karena memiliki performa yang konsisten tinggi di semua metrik.

# Analisis Berdasarkan confusion_matrix
"""

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Contoh Confusion Matrix untuk Logistic Regression
y_pred_logreg = logreg_model.predict(X_test)
cm_logreg = confusion_matrix(y_test, y_pred_logreg)

plt.figure(figsize=(6, 4))
sns.heatmap(cm_logreg, annot=True, fmt="d", cmap="Blues", xticklabels=['No Diabetes', 'Diabetes'], yticklabels=['No Diabetes', 'Diabetes'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Logistic Regression')
plt.show()

"""### Analisis Berdasarkan Confusion Matrix untuk Logistic Regression

Confusion Matrix merupakan salah satu metode evaluasi yang berguna untuk menganalisis performa model klasifikasi. Pada grafik di atas, matriks menunjukkan bagaimana model Logistic Regression memprediksi kelas **"Diabetes"** (1) dan **"No Diabetes"** (0) berdasarkan data uji.

**Interpretasi Confusion Matrix:**
- **True Negative (TN)**: 18,137 (Prediksi "No Diabetes" benar).
- **False Positive (FP)**: 155 (Prediksi "Diabetes" salah, sebenarnya "No Diabetes").
- **False Negative (FN)**: 661 (Prediksi "No Diabetes" salah, sebenarnya "Diabetes").
- **True Positive (TP)**: 1,047 (Prediksi "Diabetes" benar).

**Kesimpulan:**
- Model berhasil memprediksi mayoritas sampel dengan benar (baik untuk "No Diabetes" maupun "Diabetes").
- Kesalahan klasifikasi terlihat pada nilai **FN (False Negative)** yang cukup tinggi (661). Ini berarti ada pasien yang sebenarnya memiliki diabetes tetapi terprediksi sebagai "No Diabetes", yang berisiko dalam konteks medis.
- Logistic Regression memberikan hasil yang seimbang, namun memerlukan perbaikan untuk mengurangi kesalahan FN melalui pengoptimalan lebih lanjut seperti **tuning threshold** atau penggunaan model yang lebih kompleks.

Confusion Matrix memberikan gambaran rinci tentang distribusi prediksi model terhadap label sebenarnya, sehingga dapat digunakan untuk mengidentifikasi area perbaikan.

"""

# Prediksi menggunakan Random Forest
y_pred_rf = rf_model.predict(X_test)

# Membuat Confusion Matrix
cm_rf = confusion_matrix(y_test, y_pred_rf)

# Visualisasi Confusion Matrix
plt.figure(figsize=(6, 4))
sns.heatmap(cm_rf, annot=True, fmt="d", cmap="Blues", xticklabels=['No Diabetes', 'Diabetes'], yticklabels=['No Diabetes', 'Diabetes'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Random Forest')
plt.show()

"""### Analisis Berdasarkan Confusion Matrix untuk Random Forest

Confusion Matrix merupakan alat evaluasi yang memberikan rincian performa model klasifikasi. Gambar di atas menunjukkan Confusion Matrix untuk model **Random Forest**.

**Interpretasi Confusion Matrix:**
- **True Negative (TN)**: 18,225 (Prediksi "No Diabetes" benar).
- **False Positive (FP)**: 67 (Prediksi "Diabetes" salah, sebenarnya "No Diabetes").
- **False Negative (FN)**: 534 (Prediksi "No Diabetes" salah, sebenarnya "Diabetes").
- **True Positive (TP)**: 1,174 (Prediksi "Diabetes" benar).

**Kesimpulan:**
- Model Random Forest menunjukkan performa yang lebih baik dibanding Logistic Regression dalam meminimalkan kesalahan prediksi.
- **False Negative (FN)** lebih rendah dibanding Logistic Regression (534 vs. 661), yang berarti Random Forest lebih baik dalam mendeteksi kasus diabetes.
- Dengan **True Positive (TP)** yang lebih tinggi (1,174), model ini memberikan prediksi yang lebih andal untuk pasien dengan diabetes.
- Kesalahan **False Positive (FP)** juga rendah (67), yang menunjukkan Random Forest jarang salah memprediksi "Diabetes" untuk pasien yang sebenarnya tidak memiliki diabetes.

Secara keseluruhan, Random Forest memberikan hasil yang sangat baik dan lebih akurat dibanding model sebelumnya, menjadikannya salah satu model yang unggul untuk kasus ini.

"""

# Prediksi menggunakan SVM
y_pred_svm = svm_model.predict(X_test)

# Membuat Confusion Matrix
cm_svm = confusion_matrix(y_test, y_pred_svm)

# Visualisasi Confusion Matrix
plt.figure(figsize=(6, 4))
sns.heatmap(cm_svm, annot=True, fmt="d", cmap="Blues", xticklabels=['No Diabetes', 'Diabetes'], yticklabels=['No Diabetes', 'Diabetes'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - SVM')
plt.show()

"""### Analisis Berdasarkan Confusion Matrix untuk SVM

Confusion Matrix di atas menampilkan evaluasi performa model **Support Vector Machine (SVM)** pada dataset uji.

**Interpretasi Confusion Matrix:**
- **True Negative (TN)**: 18,260 (Prediksi "No Diabetes" benar).
- **False Positive (FP)**: 32 (Prediksi "Diabetes" salah, sebenarnya "No Diabetes").
- **False Negative (FN)**: 766 (Prediksi "No Diabetes" salah, sebenarnya "Diabetes").
- **True Positive (TP)**: 942 (Prediksi "Diabetes" benar).

**Kesimpulan:**
- Model SVM memiliki **True Negative (TN)** yang tinggi (18,260), menunjukkan bahwa model sangat andal dalam memprediksi pasien tanpa diabetes.
- **False Positive (FP)** sangat rendah (32), yang berarti hanya sedikit kasus di mana model salah memprediksi pasien memiliki diabetes.
- Namun, **False Negative (FN)** cukup tinggi (766), yang menunjukkan bahwa model sering kali gagal mendeteksi pasien dengan diabetes. Hal ini dapat menjadi risiko jika digunakan dalam aplikasi kesehatan.
- Akurasi keseluruhan model cukup baik, namun tingkat kesalahan pada pasien dengan diabetes (FN) perlu diminimalkan lebih lanjut.

Meskipun akurasi tinggi, SVM menunjukkan kelemahan dalam recall, sehingga Random Forest masih lebih unggul dalam mendeteksi diabetes secara benar.

"""

# Prediksi menggunakan model Deep Learning
y_pred_dl = (model_dl.predict(X_test) > 0.5).astype("int32")  # Konversi probabilitas ke kelas biner

# Membuat Confusion Matrix
cm_dl = confusion_matrix(y_test, y_pred_dl)

# Visualisasi Confusion Matrix
plt.figure(figsize=(6, 4))
sns.heatmap(cm_dl, annot=True, fmt="d", cmap="Blues", xticklabels=['No Diabetes', 'Diabetes'], yticklabels=['No Diabetes', 'Diabetes'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Deep Learning')
plt.show()

"""### Analisis Berdasarkan Confusion Matrix untuk Deep Learning

Confusion Matrix di atas menampilkan evaluasi performa model **Deep Learning** pada dataset uji.

**Interpretasi Confusion Matrix:**
- **True Negative (TN)**: 18,211 (Prediksi "No Diabetes" benar).
- **False Positive (FP)**: 81 (Prediksi "Diabetes" salah, sebenarnya "No Diabetes").
- **False Negative (FN)**: 538 (Prediksi "No Diabetes" salah, sebenarnya "Diabetes").
- **True Positive (TP)**: 1,170 (Prediksi "Diabetes" benar).

**Kesimpulan:**
- Model Deep Learning memiliki **True Negative (TN)** yang tinggi, dengan 18,211 kasus tanpa diabetes yang terdeteksi dengan benar.
- **False Positive (FP)** sangat rendah (81), menunjukkan bahwa model jarang salah memprediksi pasien memiliki diabetes.
- **True Positive (TP)** juga cukup tinggi (1,170), mengindikasikan bahwa model cukup andal dalam mendeteksi pasien yang benar-benar memiliki diabetes.
- Namun, **False Negative (FN)** sebesar 538 menunjukkan bahwa model masih sering gagal mendeteksi diabetes pada pasien yang sebenarnya memiliki penyakit tersebut.

Deep Learning menunjukkan performa yang sangat baik dengan kombinasi akurasi tinggi, False Positive rendah, dan kemampuan deteksi diabetes yang kuat dibanding model lainnya.

"""

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Prediksi untuk setiap model
y_pred_logreg = logreg_model.predict(X_test)
y_pred_rf = rf_model.predict(X_test)
y_pred_svm = svm_model.predict(X_test)
y_pred_dl = (model_dl.predict(X_test) > 0.5).astype("int32")  # Konversi probabilitas ke kelas biner

# Membuat Confusion Matrix untuk setiap model
cm_logreg = confusion_matrix(y_test, y_pred_logreg)
cm_rf = confusion_matrix(y_test, y_pred_rf)
cm_svm = confusion_matrix(y_test, y_pred_svm)
cm_dl = confusion_matrix(y_test, y_pred_dl)

# Membuat subplots untuk menampilkan keempat Confusion Matrix
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# Confusion Matrix untuk Logistic Regression
sns.heatmap(cm_logreg, annot=True, fmt="d", cmap="Blues", xticklabels=['No Diabetes', 'Diabetes'], yticklabels=['No Diabetes', 'Diabetes'], ax=axes[0, 0])
axes[0, 0].set_title('Confusion Matrix - Logistic Regression')
axes[0, 0].set_xlabel('Predicted')
axes[0, 0].set_ylabel('Actual')

# Confusion Matrix untuk Random Forest
sns.heatmap(cm_rf, annot=True, fmt="d", cmap="Blues", xticklabels=['No Diabetes', 'Diabetes'], yticklabels=['No Diabetes', 'Diabetes'], ax=axes[0, 1])
axes[0, 1].set_title('Confusion Matrix - Random Forest')
axes[0, 1].set_xlabel('Predicted')
axes[0, 1].set_ylabel('Actual')

# Confusion Matrix untuk SVM
sns.heatmap(cm_svm, annot=True, fmt="d", cmap="Blues", xticklabels=['No Diabetes', 'Diabetes'], yticklabels=['No Diabetes', 'Diabetes'], ax=axes[1, 0])
axes[1, 0].set_title('Confusion Matrix - SVM')
axes[1, 0].set_xlabel('Predicted')
axes[1, 0].set_ylabel('Actual')

# Confusion Matrix untuk Deep Learning
sns.heatmap(cm_dl, annot=True, fmt="d", cmap="Blues", xticklabels=['No Diabetes', 'Diabetes'], yticklabels=['No Diabetes', 'Diabetes'], ax=axes[1, 1])
axes[1, 1].set_title('Confusion Matrix - Deep Learning')
axes[1, 1].set_xlabel('Predicted')
axes[1, 1].set_ylabel('Actual')

# Menampilkan semua Confusion Matrix
plt.tight_layout()
plt.show()

"""### Analisis Berdasarkan Confusion Matrix untuk Semua Model

Confusion Matrix di atas memberikan gambaran performa setiap model pada dataset uji, yaitu **Logistic Regression**, **Random Forest**, **SVM**, dan **Deep Learning**.

#### **1. Logistic Regression**
- **True Negative (TN)**: 18,137 (Prediksi "No Diabetes" benar).
- **False Positive (FP)**: 155 (Prediksi "Diabetes" salah, sebenarnya "No Diabetes").
- **False Negative (FN)**: 661 (Prediksi "No Diabetes" salah, sebenarnya "Diabetes").
- **True Positive (TP)**: 1,047 (Prediksi "Diabetes" benar).

#### **2. Random Forest**
- **True Negative (TN)**: 18,225.
- **False Positive (FP)**: 67.
- **False Negative (FN)**: 534.
- **True Positive (TP)**: 1,174.

#### **3. SVM**
- **True Negative (TN)**: 18,260.
- **False Positive (FP)**: 32.
- **False Negative (FN)**: 766.
- **True Positive (TP)**: 942.

#### **4. Deep Learning**
- **True Negative (TN)**: 18,211.
- **False Positive (FP)**: 81.
- **False Negative (FN)**: 538.
- **True Positive (TP)**: 1,170.

### **Kesimpulan**
1. **Akurasi Tinggi**: Random Forest dan Deep Learning memiliki performa terbaik dalam hal akurasi.
2. **False Positives**: SVM menunjukkan tingkat **False Positives** yang paling rendah (hanya 32).
3. **True Positives**: Random Forest dan Deep Learning mendeteksi lebih banyak kasus diabetes dengan benar dibandingkan Logistic Regression dan SVM.
4. **False Negatives**: Deep Learning memiliki **False Negatives** yang lebih rendah dibandingkan Logistic Regression dan SVM, sehingga lebih andal dalam mendeteksi pasien dengan diabetes.

Secara keseluruhan, **Random Forest** dan **Deep Learning** adalah model yang direkomendasikan untuk tugas prediksi ini, dengan keseimbangan baik antara akurasi tinggi dan kemampuan mendeteksi diabetes.

"""

import joblib

# Menyimpan model Logistic Regression
joblib.dump(logreg_model, 'logistic_regression_model.pkl')

# Menyimpan model Random Forest
joblib.dump(rf_model, 'random_forest_model.pkl')

# Menyimpan model SVM
joblib.dump(svm_model, 'svm_model.pkl')

# Menyimpan model dalam format .keras
model_dl.save('deep_learning_model.keras')

"""### Menyimpan Model yang Telah Dilatih

Pada tahap ini, model yang telah dilatih disimpan untuk digunakan kembali di masa mendatang tanpa perlu melatih ulang model dari awal. Berikut adalah penjelasan mengenai proses penyimpanan model:

#### **1. Model Logistic Regression**
- Model Logistic Regression disimpan menggunakan library **joblib** dalam format `.pkl`.
- File model: `logistic_regression_model.pkl`.

#### **2. Model Random Forest**
- Model Random Forest disimpan dalam format `.pkl` menggunakan library **joblib**.
- File model: `random_forest_model.pkl`.

#### **3. Model SVM**
- Model SVM disimpan menggunakan **joblib** dengan format `.pkl`.
- File model: `svm_model.pkl`.

#### **4. Model Deep Learning**
- Model Deep Learning disimpan dalam format `.keras` menggunakan metode bawaan Keras (`model.save`).
- File model: `deep_learning_model.keras`.

### **Keuntungan Menyimpan Model**
- **Efisiensi Waktu**: Model yang sudah disimpan dapat langsung digunakan untuk prediksi tanpa melatih ulang.
- **Kemudahan Integrasi**: Model yang disimpan dapat diintegrasikan ke dalam aplikasi atau layanan tanpa harus menyertakan kode pelatihan.

"""